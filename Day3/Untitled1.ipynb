{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c6ec99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures,LabelEncoder\n",
    "from sklearn.model_selection import KFold,train_test_split,GridSearchCV,RandomizedSearchCV, StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "014647f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Department</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>sales</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>support</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14995 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.10             0.77               6   \n",
       "3                    0.92             0.85               5   \n",
       "4                    0.89             1.00               5   \n",
       "...                   ...              ...             ...   \n",
       "14990                0.40             0.57               2   \n",
       "14991                0.37             0.48               2   \n",
       "14992                0.37             0.53               2   \n",
       "14993                0.11             0.96               6   \n",
       "14994                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       247                   4              0     1   \n",
       "3                       259                   5              0     1   \n",
       "4                       224                   5              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14990                   151                   3              0     1   \n",
       "14991                   160                   3              0     1   \n",
       "14992                   143                   3              0     1   \n",
       "14993                   280                   4              0     1   \n",
       "14994                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years Department  salary  \n",
       "0                          0      sales     low  \n",
       "1                          0      sales  medium  \n",
       "2                          0      sales     low  \n",
       "3                          0      sales     low  \n",
       "4                          0      sales     low  \n",
       "...                      ...        ...     ...  \n",
       "14990                      0    support     low  \n",
       "14991                      0    support     low  \n",
       "14992                      0    support     low  \n",
       "14993                      0    support     low  \n",
       "14994                      0    support     low  \n",
       "\n",
       "[14995 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr  = pd.read_csv(r\"C:\\Users\\Anonymous\\Desktop\\Machine Learning\\human-resources-analytics\\HR_comma_sep.csv\")\n",
    "hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88473ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>satisfaction_level</th>\n",
       "      <th>last_evaluation</th>\n",
       "      <th>number_project</th>\n",
       "      <th>average_montly_hours</th>\n",
       "      <th>time_spend_company</th>\n",
       "      <th>Work_accident</th>\n",
       "      <th>left</th>\n",
       "      <th>promotion_last_5years</th>\n",
       "      <th>Department_RandD</th>\n",
       "      <th>Department_accounting</th>\n",
       "      <th>Department_hr</th>\n",
       "      <th>Department_management</th>\n",
       "      <th>Department_marketing</th>\n",
       "      <th>Department_product_mng</th>\n",
       "      <th>Department_sales</th>\n",
       "      <th>Department_support</th>\n",
       "      <th>Department_technical</th>\n",
       "      <th>salary_low</th>\n",
       "      <th>salary_medium</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.38</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>157</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>5</td>\n",
       "      <td>262</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.10</td>\n",
       "      <td>0.77</td>\n",
       "      <td>6</td>\n",
       "      <td>247</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.92</td>\n",
       "      <td>0.85</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>1.00</td>\n",
       "      <td>5</td>\n",
       "      <td>224</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14990</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.57</td>\n",
       "      <td>2</td>\n",
       "      <td>151</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14991</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.48</td>\n",
       "      <td>2</td>\n",
       "      <td>160</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14992</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.53</td>\n",
       "      <td>2</td>\n",
       "      <td>143</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14993</th>\n",
       "      <td>0.11</td>\n",
       "      <td>0.96</td>\n",
       "      <td>6</td>\n",
       "      <td>280</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14994</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.52</td>\n",
       "      <td>2</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14995 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       satisfaction_level  last_evaluation  number_project  \\\n",
       "0                    0.38             0.53               2   \n",
       "1                    0.80             0.86               5   \n",
       "2                    0.10             0.77               6   \n",
       "3                    0.92             0.85               5   \n",
       "4                    0.89             1.00               5   \n",
       "...                   ...              ...             ...   \n",
       "14990                0.40             0.57               2   \n",
       "14991                0.37             0.48               2   \n",
       "14992                0.37             0.53               2   \n",
       "14993                0.11             0.96               6   \n",
       "14994                0.37             0.52               2   \n",
       "\n",
       "       average_montly_hours  time_spend_company  Work_accident  left  \\\n",
       "0                       157                   3              0     1   \n",
       "1                       262                   6              0     1   \n",
       "2                       247                   4              0     1   \n",
       "3                       259                   5              0     1   \n",
       "4                       224                   5              0     1   \n",
       "...                     ...                 ...            ...   ...   \n",
       "14990                   151                   3              0     1   \n",
       "14991                   160                   3              0     1   \n",
       "14992                   143                   3              0     1   \n",
       "14993                   280                   4              0     1   \n",
       "14994                   158                   3              0     1   \n",
       "\n",
       "       promotion_last_5years  Department_RandD  Department_accounting  \\\n",
       "0                          0                 0                      0   \n",
       "1                          0                 0                      0   \n",
       "2                          0                 0                      0   \n",
       "3                          0                 0                      0   \n",
       "4                          0                 0                      0   \n",
       "...                      ...               ...                    ...   \n",
       "14990                      0                 0                      0   \n",
       "14991                      0                 0                      0   \n",
       "14992                      0                 0                      0   \n",
       "14993                      0                 0                      0   \n",
       "14994                      0                 0                      0   \n",
       "\n",
       "       Department_hr  Department_management  Department_marketing  \\\n",
       "0                  0                      0                     0   \n",
       "1                  0                      0                     0   \n",
       "2                  0                      0                     0   \n",
       "3                  0                      0                     0   \n",
       "4                  0                      0                     0   \n",
       "...              ...                    ...                   ...   \n",
       "14990              0                      0                     0   \n",
       "14991              0                      0                     0   \n",
       "14992              0                      0                     0   \n",
       "14993              0                      0                     0   \n",
       "14994              0                      0                     0   \n",
       "\n",
       "       Department_product_mng  Department_sales  Department_support  \\\n",
       "0                           0                 1                   0   \n",
       "1                           0                 1                   0   \n",
       "2                           0                 1                   0   \n",
       "3                           0                 1                   0   \n",
       "4                           0                 1                   0   \n",
       "...                       ...               ...                 ...   \n",
       "14990                       0                 0                   1   \n",
       "14991                       0                 0                   1   \n",
       "14992                       0                 0                   1   \n",
       "14993                       0                 0                   1   \n",
       "14994                       0                 0                   1   \n",
       "\n",
       "       Department_technical  salary_low  salary_medium  \n",
       "0                         0           1              0  \n",
       "1                         0           0              1  \n",
       "2                         0           1              0  \n",
       "3                         0           1              0  \n",
       "4                         0           1              0  \n",
       "...                     ...         ...            ...  \n",
       "14990                     0           1              0  \n",
       "14991                     0           1              0  \n",
       "14992                     0           1              0  \n",
       "14993                     0           1              0  \n",
       "14994                     0           1              0  \n",
       "\n",
       "[14995 rows x 19 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_dum = pd.get_dummies(hr,drop_first=True)\n",
    "hr_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7216ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hr_dum.drop('left',axis=1)\n",
    "y = hr_dum['left']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a8b2d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.21574026  0.22936451 -0.30248641  0.00468768  0.24795574 -1.49304109\n",
      "  -0.69083706 -0.4664561  -0.00760262  0.34256229 -0.69647083 -0.06283616\n",
      "   0.05185786 -0.01113399  0.21671357  0.16424592  1.42572282  0.99616913]]\n",
      "0.2078239608801956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=10,test_size=0.3)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr.coef_)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(mean_squared_error(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f167eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42935834392841077\n"
     ]
    }
   ],
   "source": [
    "y_pred_prob = lr.predict_proba(X_test)\n",
    "print(log_loss(y_test,y_pred_prob[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05a841d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.20046682227409135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "##################KFold CV ####################333333\n",
    "kfold = KFold(n_splits=5,shuffle=True,random_state=23)\n",
    "results = cross_val_score(lr,X,y,scoring = 'neg_mean_squared_error',cv = kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c075d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "[CV 1/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.500 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.511 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.505 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.530 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.511 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.505 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.500 total time=   0.2s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.509 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.449 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.449 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.449 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.437 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.437 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.421 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.425 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.425 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.425 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.425 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.425 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.425 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.425 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.425 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.425 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.425 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.1s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.429 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.429 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.436 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.436 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.422 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.429 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.436 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.429 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.436 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.422 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.429 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.436 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.436 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.436 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.422 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.429 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.436 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.429 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.436 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.429 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.436 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.429 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.437 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.437 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.437 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.437 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.437 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.428 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.438 total time=   0.1s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.422 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.428 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.430 total time=   0.2s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.430 total time=   0.1s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.423 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.1s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.1s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.1s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.445 total time=   0.0s\n",
      "[CV 2/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.428 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.446 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.445 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.438 total time= 6.6min\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.422 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.446 total time=   0.3s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.438 total time=   0.1s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.445 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.428 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.438 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.422 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.446 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.430 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.438 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.423 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.445 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.428 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.438 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.422 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.446 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.430 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.438 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.423 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.445 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.428 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.438 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.422 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.446 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.430 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.438 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.423 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.428 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.445 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.428 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.430 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.423 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.445 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.428 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.422 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.438 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.423 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.428 total time=   0.1s\n",
      "[CV 1/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.445 total time=   0.1s\n",
      "[CV 2/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.428 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.422 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.428 total time=   0.2s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, penalty=elasticinet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.446 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.430 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.438 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.423 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1000 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l2', 'elasticnet', 'none' (deprecated), 'l1'} or None. Got 'elasticinet' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan -0.51108532         nan -0.43305641         nan -0.51108532\n",
      "         nan -0.43305641         nan -0.51108532         nan -0.43305641\n",
      "         nan -0.51108532         nan -0.43305641         nan -0.51108532\n",
      "         nan -0.43305641         nan -0.51108532         nan -0.43305641\n",
      "         nan -0.51108532         nan -0.43305641         nan -0.51108532\n",
      "         nan -0.43305641         nan -0.51108532         nan -0.43305641\n",
      "         nan -0.51108532         nan -0.43305641         nan -0.43335047\n",
      "         nan -0.43305641         nan -0.43335047         nan -0.43305641\n",
      "         nan -0.43335047         nan -0.43305641         nan -0.43335047\n",
      "         nan -0.43305641         nan -0.43335047         nan -0.43305641\n",
      "         nan -0.43335047         nan -0.43305641         nan -0.43335047\n",
      "         nan -0.43305641         nan -0.43335047         nan -0.43305641\n",
      "         nan -0.43335047         nan -0.43305641         nan -0.43335047\n",
      "         nan -0.43305641         nan -0.43242988         nan -0.43305641\n",
      "         nan -0.43242988         nan -0.43305641         nan -0.43242988\n",
      "         nan -0.43305641         nan -0.43242988         nan -0.43305641\n",
      "         nan -0.43242988         nan -0.43305641         nan -0.43242988\n",
      "         nan -0.43305641         nan -0.43242988         nan -0.43305641\n",
      "         nan -0.43242988         nan -0.43305641         nan -0.43242988\n",
      "         nan -0.43305641         nan -0.43242988         nan -0.43305641\n",
      "         nan -0.4328439          nan -0.43305641         nan -0.4328439\n",
      "         nan -0.43305641         nan -0.4328439          nan -0.43305641\n",
      "         nan -0.4328439          nan -0.43305641         nan -0.4328439\n",
      "         nan -0.43305641         nan -0.4328439          nan -0.43305641\n",
      "         nan -0.4328439          nan -0.43305641         nan -0.4328439\n",
      "         nan -0.43305641         nan -0.4328439          nan -0.43305641\n",
      "         nan -0.4328439          nan -0.43305641         nan -0.43265157\n",
      "         nan -0.43305641         nan -0.43265157         nan -0.43305641\n",
      "         nan -0.43265157         nan -0.43305641         nan -0.43265157\n",
      "         nan -0.43305641         nan -0.43265157         nan -0.43305641\n",
      "         nan -0.43265157         nan -0.43305641         nan -0.43265157\n",
      "         nan -0.43305641         nan -0.43265157         nan -0.43305641\n",
      "         nan -0.43265157         nan -0.43305641         nan -0.43265157\n",
      "         nan -0.43305641         nan -0.43243628         nan -0.43305641\n",
      "         nan -0.43243628         nan -0.43305641         nan -0.43243628\n",
      "         nan -0.43305641         nan -0.43243628         nan -0.43305641\n",
      "         nan -0.43243628         nan -0.43305641         nan -0.43243628\n",
      "         nan -0.43305641         nan -0.43243628         nan -0.43305641\n",
      "         nan -0.43243628         nan -0.43305641         nan -0.43243628\n",
      "         nan -0.43305641         nan -0.43243628         nan -0.43305641\n",
      "         nan -0.43256473         nan -0.43305641         nan -0.43256473\n",
      "         nan -0.43305641         nan -0.43256473         nan -0.43305641\n",
      "         nan -0.43256473         nan -0.43305641         nan -0.43256473\n",
      "         nan -0.43305641         nan -0.43256473         nan -0.43305641\n",
      "         nan -0.43256473         nan -0.43305641         nan -0.43256473\n",
      "         nan -0.43305641         nan -0.43256473         nan -0.43305641\n",
      "         nan -0.43256473         nan -0.43305641         nan -0.43264642\n",
      "         nan -0.43305641         nan -0.43264642         nan -0.43305641\n",
      "         nan -0.43264642         nan -0.43305641         nan -0.43264642\n",
      "         nan -0.43305641         nan -0.43264642         nan -0.43305641\n",
      "         nan -0.43264642         nan -0.43305641         nan -0.43264642\n",
      "         nan -0.43305641         nan -0.43264642         nan -0.43305641\n",
      "         nan -0.43264642         nan -0.43305641         nan -0.43264642\n",
      "         nan -0.43305641         nan -0.43272464         nan -0.43305641\n",
      "         nan -0.43272464         nan -0.43305641         nan -0.43272464\n",
      "         nan -0.43305641         nan -0.43272464         nan -0.43305641\n",
      "         nan -0.43272464         nan -0.43305641         nan -0.43272464\n",
      "         nan -0.43305641         nan -0.43272464         nan -0.43305641\n",
      "         nan -0.43272464         nan -0.43305641         nan -0.43272464\n",
      "         nan -0.43305641         nan -0.43272464         nan -0.43305641\n",
      "         nan -0.43233131         nan -0.43305641         nan -0.43233131\n",
      "         nan -0.43305641         nan -0.43233131         nan -0.43305641\n",
      "         nan -0.43233131         nan -0.43305641         nan -0.43233131\n",
      "         nan -0.43305641         nan -0.43233131         nan -0.43305641\n",
      "         nan -0.43233131         nan -0.43305641         nan -0.43233131\n",
      "         nan -0.43305641         nan -0.43233131         nan -0.43305641\n",
      "         nan -0.43233131         nan -0.43305641]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.428 total time=   0.1s\n",
      "{'C': 5.0, 'l1_ratio': 0.0, 'penalty': 'l2'}\n",
      "-0.4323313119769784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "###################### Grid CV Search\n",
    "params = {'penalty' : ['l1','l2','elasticinet',None],'C':np.linspace(0.001,5,10),'l1_ratio':np.linspace(0,1,10)}\n",
    "lr = LogisticRegression()\n",
    "gcv = GridSearchCV(lr,param_grid=params,verbose = 3,scoring = 'neg_log_loss',cv = kfold)\n",
    "gcv.fit(X,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6c70a01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Clump</th>\n",
       "      <th>UniCell_Size</th>\n",
       "      <th>Uni_CellShape</th>\n",
       "      <th>MargAdh</th>\n",
       "      <th>SEpith</th>\n",
       "      <th>BareN</th>\n",
       "      <th>BChromatin</th>\n",
       "      <th>NoemN</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61634</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63375</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76389</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95719</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>1369821</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1371026</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1371920</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>8233704</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>13454352</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Code  Clump  UniCell_Size  Uni_CellShape  MargAdh  SEpith  BareN  \\\n",
       "0       61634      5             4              3        1       2      2   \n",
       "1       63375      9             1              2        6       4     10   \n",
       "2       76389     10             4              7        2       2      8   \n",
       "3       95719      6            10             10       10       8     10   \n",
       "4      128059      1             1              1        1       2      5   \n",
       "..        ...    ...           ...            ...      ...     ...    ...   \n",
       "694   1369821     10            10             10       10       5     10   \n",
       "695   1371026      5            10             10       10       4     10   \n",
       "696   1371920      5             1              1        1       2      1   \n",
       "697   8233704      4             1              1        1       1      1   \n",
       "698  13454352      1             1              3        1       2      1   \n",
       "\n",
       "     BChromatin  NoemN  Mitoses      Class  \n",
       "0             2      3        1     Benign  \n",
       "1             7      7        2  Malignant  \n",
       "2             6      1        1  Malignant  \n",
       "3             7     10        7  Malignant  \n",
       "4             5      1        1     Benign  \n",
       "..          ...    ...      ...        ...  \n",
       "694          10     10        7  Malignant  \n",
       "695           5      6        3  Malignant  \n",
       "696           3      2        1     Benign  \n",
       "697           2      1        1     Benign  \n",
       "698           2      1        1     Benign  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = pd.read_csv(r\"C:\\Users\\Anonymous\\Desktop\\Machine Learning\\Cases\\BreastCancer.csv\")\n",
    "breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94e2b43c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Clump</th>\n",
       "      <th>UniCell_Size</th>\n",
       "      <th>Uni_CellShape</th>\n",
       "      <th>MargAdh</th>\n",
       "      <th>SEpith</th>\n",
       "      <th>BareN</th>\n",
       "      <th>BChromatin</th>\n",
       "      <th>NoemN</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class_Malignant</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61634</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63375</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76389</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95719</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>1369821</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1371026</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1371920</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>8233704</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>13454352</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Code  Clump  UniCell_Size  Uni_CellShape  MargAdh  SEpith  BareN  \\\n",
       "0       61634      5             4              3        1       2      2   \n",
       "1       63375      9             1              2        6       4     10   \n",
       "2       76389     10             4              7        2       2      8   \n",
       "3       95719      6            10             10       10       8     10   \n",
       "4      128059      1             1              1        1       2      5   \n",
       "..        ...    ...           ...            ...      ...     ...    ...   \n",
       "694   1369821     10            10             10       10       5     10   \n",
       "695   1371026      5            10             10       10       4     10   \n",
       "696   1371920      5             1              1        1       2      1   \n",
       "697   8233704      4             1              1        1       1      1   \n",
       "698  13454352      1             1              3        1       2      1   \n",
       "\n",
       "     BChromatin  NoemN  Mitoses  Class_Malignant  \n",
       "0             2      3        1                0  \n",
       "1             7      7        2                1  \n",
       "2             6      1        1                1  \n",
       "3             7     10        7                1  \n",
       "4             5      1        1                0  \n",
       "..          ...    ...      ...              ...  \n",
       "694          10     10        7                1  \n",
       "695           5      6        3                1  \n",
       "696           3      2        1                0  \n",
       "697           2      1        1                0  \n",
       "698           2      1        1                0  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_cancer = pd.get_dummies(breast_cancer,drop_first=True)\n",
    "dum_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "209a9b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dum_cancer.drop(['Code','Class_Malignant'],axis = 1)\n",
    "y = dum_cancer['Class_Malignant']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "701f2b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01904761904761905\n",
      "-0.040051387461459406\n"
     ]
    }
   ],
   "source": [
    "X_train ,X_test , y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=12)\n",
    "\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "kfold = KFold(n_splits=5,shuffle=True,random_state=23)\n",
    "results = cross_val_score(gnb,X,y,scoring = 'neg_mean_squared_error',cv = kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "48d1c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.60747779 -0.09680991  0.34383189  0.54398814  0.05036286  0.53134921\n",
      "   0.39437547  0.18042427  0.5239153 ]]\n",
      "0.047619047619047616\n",
      "0.15403977509301497\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=10,test_size=0.3)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "print(lr.coef_)\n",
    "y_pred = lr.predict(X_test)\n",
    "print(mean_squared_error(y_test,y_pred))\n",
    "\n",
    "y_pred_prob = lr.predict_proba(X_test)\n",
    "print(log_loss(y_test,y_pred_prob[:,1]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "069523a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n",
      "[CV 1/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.139 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.196 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.178 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.196 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.166 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=1.0, penalty=l2;, score=-0.171 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.141 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.138 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.052 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.052 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.138 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.143 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.139 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.139 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.139 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.139 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.143 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.139 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.062 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.139 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=l2;, score=-0.141 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=l2;, score=-0.142 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.144 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.144 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.144 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.142 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.061 total time=   0.2s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.144 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=l2;, score=-0.142 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.143 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.143 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.145 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=5.0, l1_ratio=0.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END ..C=5.0, l1_ratio=0.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.061 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.146 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.146 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.140 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, penalty=None;, score=-0.144 total time=   0.0s\n",
      "[CV 1/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=5.0, l1_ratio=1.0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.053 total time=   0.0s\n",
      "[CV 3/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.145 total time=   0.0s\n",
      "[CV 5/5] END ..C=5.0, l1_ratio=1.0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.061 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.053 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.140 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.146 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, penalty=None;, score=-0.144 total time=   0.0s\n",
      "{'C': 0.5564444444444444, 'l1_ratio': 0.0, 'penalty': 'l2'}\n",
      "-0.10632161442848272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "1000 fits failed out of a total of 2000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "500 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan -0.17002679         nan -0.10880435         nan -0.17002679\n",
      "         nan -0.10880435         nan -0.17002679         nan -0.10880435\n",
      "         nan -0.17002679         nan -0.10880435         nan -0.17002679\n",
      "         nan -0.10880435         nan -0.17002679         nan -0.10880435\n",
      "         nan -0.17002679         nan -0.10880435         nan -0.17002679\n",
      "         nan -0.10880435         nan -0.17002679         nan -0.10880435\n",
      "         nan -0.17002679         nan -0.10880435         nan -0.10632161\n",
      "         nan -0.10880435         nan -0.10632161         nan -0.10880435\n",
      "         nan -0.10632161         nan -0.10880435         nan -0.10632161\n",
      "         nan -0.10880435         nan -0.10632161         nan -0.10880435\n",
      "         nan -0.10632161         nan -0.10880435         nan -0.10632161\n",
      "         nan -0.10880435         nan -0.10632161         nan -0.10880435\n",
      "         nan -0.10632161         nan -0.10880435         nan -0.10632161\n",
      "         nan -0.10880435         nan -0.10741085         nan -0.10880435\n",
      "         nan -0.10741085         nan -0.10880435         nan -0.10741085\n",
      "         nan -0.10880435         nan -0.10741085         nan -0.10880435\n",
      "         nan -0.10741085         nan -0.10880435         nan -0.10741085\n",
      "         nan -0.10880435         nan -0.10741085         nan -0.10880435\n",
      "         nan -0.10741085         nan -0.10880435         nan -0.10741085\n",
      "         nan -0.10880435         nan -0.10741085         nan -0.10880435\n",
      "         nan -0.10783376         nan -0.10880435         nan -0.10783376\n",
      "         nan -0.10880435         nan -0.10783376         nan -0.10880435\n",
      "         nan -0.10783376         nan -0.10880435         nan -0.10783376\n",
      "         nan -0.10880435         nan -0.10783376         nan -0.10880435\n",
      "         nan -0.10783376         nan -0.10880435         nan -0.10783376\n",
      "         nan -0.10880435         nan -0.10783376         nan -0.10880435\n",
      "         nan -0.10783376         nan -0.10880435         nan -0.10806005\n",
      "         nan -0.10880435         nan -0.10806005         nan -0.10880435\n",
      "         nan -0.10806005         nan -0.10880435         nan -0.10806005\n",
      "         nan -0.10880435         nan -0.10806005         nan -0.10880435\n",
      "         nan -0.10806005         nan -0.10880435         nan -0.10806005\n",
      "         nan -0.10880435         nan -0.10806005         nan -0.10880435\n",
      "         nan -0.10806005         nan -0.10880435         nan -0.10806005\n",
      "         nan -0.10880435         nan -0.10820191         nan -0.10880435\n",
      "         nan -0.10820191         nan -0.10880435         nan -0.10820191\n",
      "         nan -0.10880435         nan -0.10820191         nan -0.10880435\n",
      "         nan -0.10820191         nan -0.10880435         nan -0.10820191\n",
      "         nan -0.10880435         nan -0.10820191         nan -0.10880435\n",
      "         nan -0.10820191         nan -0.10880435         nan -0.10820191\n",
      "         nan -0.10880435         nan -0.10820191         nan -0.10880435\n",
      "         nan -0.10829667         nan -0.10880435         nan -0.10829667\n",
      "         nan -0.10880435         nan -0.10829667         nan -0.10880435\n",
      "         nan -0.10829667         nan -0.10880435         nan -0.10829667\n",
      "         nan -0.10880435         nan -0.10829667         nan -0.10880435\n",
      "         nan -0.10829667         nan -0.10880435         nan -0.10829667\n",
      "         nan -0.10880435         nan -0.10829667         nan -0.10880435\n",
      "         nan -0.10829667         nan -0.10880435         nan -0.10836516\n",
      "         nan -0.10880435         nan -0.10836516         nan -0.10880435\n",
      "         nan -0.10836516         nan -0.10880435         nan -0.10836516\n",
      "         nan -0.10880435         nan -0.10836516         nan -0.10880435\n",
      "         nan -0.10836516         nan -0.10880435         nan -0.10836516\n",
      "         nan -0.10880435         nan -0.10836516         nan -0.10880435\n",
      "         nan -0.10836516         nan -0.10880435         nan -0.10836516\n",
      "         nan -0.10880435         nan -0.10841863         nan -0.10880435\n",
      "         nan -0.10841863         nan -0.10880435         nan -0.10841863\n",
      "         nan -0.10880435         nan -0.10841863         nan -0.10880435\n",
      "         nan -0.10841863         nan -0.10880435         nan -0.10841863\n",
      "         nan -0.10880435         nan -0.10841863         nan -0.10880435\n",
      "         nan -0.10841863         nan -0.10880435         nan -0.10841863\n",
      "         nan -0.10880435         nan -0.10841863         nan -0.10880435\n",
      "         nan -0.10845884         nan -0.10880435         nan -0.10845884\n",
      "         nan -0.10880435         nan -0.10845884         nan -0.10880435\n",
      "         nan -0.10845884         nan -0.10880435         nan -0.10845884\n",
      "         nan -0.10880435         nan -0.10845884         nan -0.10880435\n",
      "         nan -0.10845884         nan -0.10880435         nan -0.10845884\n",
      "         nan -0.10880435         nan -0.10845884         nan -0.10880435\n",
      "         nan -0.10845884         nan -0.10880435]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#### KFold \n",
    "kfold = KFold(n_splits=5,shuffle=True,random_state=12)\n",
    "###################### Grid CV Search\n",
    "params = {'penalty' : ['l1','l2','elasticnet',None],'C':np.linspace(0.001,5,10),'l1_ratio':np.linspace(0,1,10)}\n",
    "lr = LogisticRegression()\n",
    "gcv = GridSearchCV(lr,param_grid=params,verbose = 3,scoring = 'neg_log_loss',cv = kfold)\n",
    "gcv.fit(X,y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9424733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>Clump</th>\n",
       "      <th>UniCell_Size</th>\n",
       "      <th>Uni_CellShape</th>\n",
       "      <th>MargAdh</th>\n",
       "      <th>SEpith</th>\n",
       "      <th>BareN</th>\n",
       "      <th>BChromatin</th>\n",
       "      <th>NoemN</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61634</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>63375</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>76389</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95719</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128059</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694</th>\n",
       "      <td>1369821</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>695</th>\n",
       "      <td>1371026</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Malignant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>696</th>\n",
       "      <td>1371920</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>697</th>\n",
       "      <td>8233704</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698</th>\n",
       "      <td>13454352</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Benign</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>699 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Code  Clump  UniCell_Size  Uni_CellShape  MargAdh  SEpith  BareN  \\\n",
       "0       61634      5             4              3        1       2      2   \n",
       "1       63375      9             1              2        6       4     10   \n",
       "2       76389     10             4              7        2       2      8   \n",
       "3       95719      6            10             10       10       8     10   \n",
       "4      128059      1             1              1        1       2      5   \n",
       "..        ...    ...           ...            ...      ...     ...    ...   \n",
       "694   1369821     10            10             10       10       5     10   \n",
       "695   1371026      5            10             10       10       4     10   \n",
       "696   1371920      5             1              1        1       2      1   \n",
       "697   8233704      4             1              1        1       1      1   \n",
       "698  13454352      1             1              3        1       2      1   \n",
       "\n",
       "     BChromatin  NoemN  Mitoses      Class  \n",
       "0             2      3        1     Benign  \n",
       "1             7      7        2  Malignant  \n",
       "2             6      1        1  Malignant  \n",
       "3             7     10        7  Malignant  \n",
       "4             5      1        1     Benign  \n",
       "..          ...    ...      ...        ...  \n",
       "694          10     10        7  Malignant  \n",
       "695           5      6        3  Malignant  \n",
       "696           3      2        1     Benign  \n",
       "697           2      1        1     Benign  \n",
       "698           2      1        1     Benign  \n",
       "\n",
       "[699 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "breast_cancer = pd.read_csv(r\"C:\\Users\\Anonymous\\Desktop\\Machine Learning\\Cases\\BreastCancer.csv\")\n",
    "breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7bfc56c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Benign': 0, 'Malignant': 1}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X= breast_cancer.drop(['Code','Class'],axis = 1)\n",
    "y = breast_cancer['Class']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "dict(zip(le.classes_, np.unique(y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4f05e845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9111429647410467\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=23)\n",
    "results = cross_val_score(gnb, X, y, cv = kfold, scoring='neg_log_loss')\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d131c063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n",
      "[CV 1/5] END .....C=0.001, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=0.001, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=0.001, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=0.001, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=0.001, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, l1_ratio=0, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, l1_ratio=0, penalty=l2;, score=-0.165 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, l1_ratio=0, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, l1_ratio=0, penalty=l2;, score=-0.164 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, l1_ratio=0, penalty=l2;, score=-0.209 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.001, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=0.001, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=0.001, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=0.001, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=0.001, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, l1_ratio=1, penalty=l2;, score=-0.166 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, l1_ratio=1, penalty=l2;, score=-0.165 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, l1_ratio=1, penalty=l2;, score=-0.143 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, l1_ratio=1, penalty=l2;, score=-0.164 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, l1_ratio=1, penalty=l2;, score=-0.209 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=0.001, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.001, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.001, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.001, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.001, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.001, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=0.001, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=0.001, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=0.001, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=0.001, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=0.001, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=0.001, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.001, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.001, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.001, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.001, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0, penalty=l2;, score=-0.086 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0, penalty=l2;, score=-0.070 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0, penalty=l2;, score=-0.066 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0, penalty=l2;, score=-0.104 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0, penalty=l2;, score=-0.180 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1, penalty=l2;, score=-0.086 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1, penalty=l2;, score=-0.070 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1, penalty=l2;, score=-0.066 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1, penalty=l2;, score=-0.104 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1, penalty=l2;, score=-0.180 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0, penalty=l2;, score=-0.086 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0, penalty=l2;, score=-0.067 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0, penalty=l2;, score=-0.106 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0, penalty=l2;, score=-0.182 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1, penalty=l2;, score=-0.086 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1, penalty=l2;, score=-0.067 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1, penalty=l2;, score=-0.106 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1, penalty=l2;, score=-0.182 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0, penalty=l2;, score=-0.067 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0, penalty=l2;, score=-0.106 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0, penalty=l2;, score=-0.183 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1, penalty=l2;, score=-0.067 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1, penalty=l2;, score=-0.106 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1, penalty=l2;, score=-0.183 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0, penalty=l2;, score=-0.067 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0, penalty=l2;, score=-0.106 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0, penalty=l2;, score=-0.184 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1, penalty=l2;, score=-0.085 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1, penalty=l2;, score=-0.067 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1, penalty=l2;, score=-0.106 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1, penalty=l2;, score=-0.184 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0, penalty=l2;, score=-0.184 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1, penalty=l2;, score=-0.184 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0, penalty=l2;, score=-0.107 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0, penalty=l2;, score=-0.184 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1, penalty=l2;, score=-0.107 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1, penalty=l2;, score=-0.184 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0, penalty=l2;, score=-0.185 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1, penalty=l2;, score=-0.068 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1, penalty=l2;, score=-0.185 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0, penalty=l2;, score=-0.185 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1, penalty=l2;, score=-0.185 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......C=5.0, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=5.0, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=5.0, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=5.0, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=5.0, l1_ratio=0, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=5.0, l1_ratio=0, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END ....C=5.0, l1_ratio=0, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END ....C=5.0, l1_ratio=0, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END ....C=5.0, l1_ratio=0, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END ....C=5.0, l1_ratio=0, penalty=l2;, score=-0.185 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=5.0, l1_ratio=0, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END ..C=5.0, l1_ratio=0, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END ..C=5.0, l1_ratio=0, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END ..C=5.0, l1_ratio=0, penalty=None;, score=-0.107 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ..C=5.0, l1_ratio=0, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END .......C=5.0, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=5.0, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=5.0, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=5.0, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=5.0, l1_ratio=1, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=5.0, l1_ratio=1, penalty=l2;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END ....C=5.0, l1_ratio=1, penalty=l2;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END ....C=5.0, l1_ratio=1, penalty=l2;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END ....C=5.0, l1_ratio=1, penalty=l2;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END ....C=5.0, l1_ratio=1, penalty=l2;, score=-0.185 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=5.0, l1_ratio=1, penalty=None;, score=-0.085 total time=   0.0s\n",
      "[CV 2/5] END ..C=5.0, l1_ratio=1, penalty=None;, score=-0.069 total time=   0.0s\n",
      "[CV 3/5] END ..C=5.0, l1_ratio=1, penalty=None;, score=-0.068 total time=   0.0s\n",
      "[CV 4/5] END ..C=5.0, l1_ratio=1, penalty=None;, score=-0.107 total time=   0.0s\n",
      "[CV 5/5] END ..C=5.0, l1_ratio=1, penalty=None;, score=-0.186 total time=   0.0s\n",
      "[CV 1/5] END ......C=5.0, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=5.0, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=5.0, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=5.0, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=None)\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ......C=5.0, l1_ratio=10, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......C=5.0, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=5.0, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=5.0, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=5.0, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=5.0, l1_ratio=10, penalty=l2;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=10, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ....C=5.0, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=5.0, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=5.0, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=5.0, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=5.0, l1_ratio=10, penalty=None;, score=nan total time=   0.0s\n",
      "{'C': 0.5564444444444444, 'l1_ratio': 0, 'penalty': 'l2'} \n",
      " -0.10111475861103751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "400 fits failed out of a total of 600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "100 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "200 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1160, in fit\n",
      "    self._validate_params()\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'l1_ratio' parameter of LogisticRegression must be a float in the range [0, 1] or None. Got 10 instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [        nan -0.16942088         nan -0.10312613         nan -0.16942088\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10111476         nan -0.10312613         nan -0.10111476\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10194675         nan -0.10312613         nan -0.10194675\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10228879         nan -0.10312613         nan -0.10228879\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10247796         nan -0.10312613         nan -0.10247796\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10259598         nan -0.10312613         nan -0.10259598\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10267891         nan -0.10312613         nan -0.10267891\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.1027386          nan -0.10312613         nan -0.1027386\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10278337         nan -0.10312613         nan -0.10278337\n",
      "         nan -0.10312613         nan         nan         nan         nan\n",
      "         nan -0.10282079         nan -0.10312613         nan -0.10282079\n",
      "         nan -0.10312613         nan         nan         nan         nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\Anonymous\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1165: UserWarning: l1_ratio parameter is only used when penalty is 'elasticnet'. Got (penalty=l2)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "print(lr.get_params())\n",
    "params = {'penalty':['l1', 'l2','elasticnet', None], 'C':np.linspace(0.001, 5, 10), 'l1_ratio':(0,1,10),}\n",
    "gcv = GridSearchCV(lr, params, verbose=3, scoring='neg_log_loss', cv=kfold)\n",
    "gcv.fit(X,y)\n",
    "print(gcv.best_params_, \"\\n\", gcv.best_score_)\n",
    "\n",
    "\n",
    "\n",
    "############### Grid Search CV ##########################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "916a11ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61c2c2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 800 candidates, totalling 4000 fits\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.439 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.480 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.490 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.483 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.430 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.470 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.484 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.475 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.476 total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.001, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.1s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.1s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.1s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.1s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.1s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.1s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.1s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.1s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.1s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.1s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.1s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.913 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.088 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.041 total time=   0.1s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.971 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.865 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.016 total time=   0.0s\n",
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=0.5564444444444444, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.1s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.1s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.1s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.1s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.889 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.030 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.1118888888888887, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.1s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.1s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.1s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.1s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.1s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.979 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.893 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.019 total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.842 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.029 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.916 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.022 total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=1.6673333333333331, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.1s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.1s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.1s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.1s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.1s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.980 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.886 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.042 total time=   0.1s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.988 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.025 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.856 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.028 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.920 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.041 total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.2227777777777775, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.1s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.1s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.1s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.1s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.981 total time=   0.1s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.883 total time=   0.1s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.035 total time=   0.1s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.000 total time=   0.1s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.034 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.032 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.836 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.938 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.061 total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=2.778222222222222, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.1s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.1s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.879 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.002 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.054 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.831 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.951 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.045 total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.3336666666666663, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.1s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.1s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.1s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.1s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.982 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.027 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.012 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.047 total time=   0.1s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.048 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.846 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.018 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.934 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.051 total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=3.8891111111111107, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.1s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.1s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.1s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.1s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.1s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.1s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.1s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.1s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=4.444555555555556, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.983 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.880 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.024 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.015 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.056 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.104 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.873 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.040 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.941 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.057 total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=4.444555555555556, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.1s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.1s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.1111111111111111, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.2222222222222222, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.1s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.3333333333333333, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.1s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.4444444444444444, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.5555555555555556, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.1s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.1s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.1s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.6666666666666666, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.7777777777777777, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.1s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.1s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.1s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END C=5.0, l1_ratio=0.8888888888888888, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.984 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-0.876 total time=   0.1s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.023 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.031 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=l2;, score=-1.062 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.737 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-0.867 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.250 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.094 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=ovr, penalty=None;, score=-1.945 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l1;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.021 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.841 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.039 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-0.943 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=l2;, score=-1.055 total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=elasticnet;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-0.845 total time=   0.0s\n",
      "[CV 3/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.053 total time=   0.0s\n",
      "[CV 4/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.030 total time=   0.0s\n",
      "[CV 5/5] END C=5.0, l1_ratio=1.0, multi_class=multinomial, penalty=None;, score=-1.115 total time=   0.0s\n",
      "{'C': 1.1118888888888887, 'l1_ratio': 0.0, 'multi_class': 'multinomial', 'penalty': 'l2'}\n",
      "-0.9622227460721575\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tst_Glass.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m best_model \u001b[38;5;241m=\u001b[39m gcv\u001b[38;5;241m.\u001b[39mbest_estimator_\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m################ Predict on the unlabelled data #########\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m tst_glass \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtst_Glass.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_model\u001b[38;5;241m.\u001b[39mpredict(tst_glass)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(le\u001b[38;5;241m.\u001b[39minverse_transform(y_pred))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tst_Glass.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "############## Glass Identification ################\n",
    "glass = pd.read_csv(r\"C:\\Users\\Anonymous\\Desktop\\Machine Learning\\Glass Identification\\Glass.csv\")\n",
    "le = LabelEncoder()\n",
    "\n",
    "X = glass.drop('Type', axis=1)\n",
    "y = glass['Type']\n",
    "y = le.fit_transform(y)\n",
    "dict(zip(le.classes_,np.unique(y)))\n",
    "\n",
    "params = {'penalty':['l1','l2','elasticnet',None],\n",
    "          'multi_class':['ovr', 'multinomial'],\n",
    "          'C': np.linspace(0.001, 5, 10),\n",
    "          'l1_ratio':np.linspace(0,1,10)}\n",
    "lr = LogisticRegression()\n",
    "gcv = GridSearchCV(lr, param_grid=params,verbose=3,\n",
    "                   scoring='neg_log_loss',\n",
    "                   cv=kfold)\n",
    "gcv.fit(X, y)\n",
    "print(gcv.best_params_)\n",
    "print(gcv.best_score_)\n",
    "\n",
    "best_model = gcv.best_estimator_\n",
    "################ Predict on the unlabelled data #########\n",
    "tst_glass = pd.read_csv(\"tst_Glass.csv\")\n",
    "y_pred = best_model.predict(tst_glass)\n",
    "\n",
    "print(le.inverse_transform(y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44561a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
